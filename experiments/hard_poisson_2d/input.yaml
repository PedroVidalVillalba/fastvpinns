# This YAML file contains configuration parameters for a variational physics-informed neural network (VarPINN) experimentation.

experimentation:
  output_path: "output"  # Path to the output directory where the results will be saved.

geometry:
  mesh_generation_method: "internal"  # Method for generating the mesh. Can be "internal" or "external".
  generate_mesh_plot: False  # Flag indicating whether to generate a plot of the mesh.
  
  mesh_type: "quadrilateral"  # Type of mesh. Can be "quadrilateral" or other supported types.

  # internal mesh generated quadrilateral mesh, depending on the parameters specified below.
  internal_mesh_params:  # Parameters for internal mesh generation method.
    x_min: 0  # Minimum x-coordinate of the domain.
    x_max: 1  # Maximum x-coordinate of the domain.
    y_min: 0  # Minimum y-coordinate of the domain.
    y_max: 1  # Maximum y-coordinate of the domain.
    n_cells_x: 16  # Number of cells in the x-direction.
    n_cells_y: 16  # Number of cells in the y-direction.
    n_boundary_points: 4  # Number of boundary points.
    n_test_points_x: 200  # Number of test points in the x-direction.
    n_test_points_y: 200  # Number of test points in the y-direction.

  
fe:
  fe_order: 8 # Order of the finite element basis functions.
  fe_type: "legendre"  # Type of finite element basis functions. Can be "jacobi" or other supported types.
  quad_order: 4  # Order of the quadrature rule.
  quad_type: "gauss-jacobi"  # Type of quadrature rule. Can be "gauss-jacobi" or other supported types.


model:
  model_architecture: [2, 50,50,50,50, 1]  # Architecture of the neural network model.
  activation: "tanh"  # Activation function used in the neural network.
  use_attention: False  # Flag indicating whether to use attention mechanism in the model.
  epochs: 10000  # Number of training epochs.
  dtype: "float32"  # Data type used for computations.
  set_memory_growth: False  # Flag indicating whether to set memory growth for GPU.
  
  learning_rate:  # Parameters for learning rate scheduling.
    initial_learning_rate: 0.001  # Initial learning rate.
    use_lr_scheduler: False  # Flag indicating whether to use learning rate scheduler.
    decay_steps: 1000  # Number of steps between each learning rate decay.
    decay_rate: 0.99  # Decay rate for the learning rate.
    staircase: False  # Flag indicating whether to use staircase decay.
  

logging:
  update_console_output: 5000  # Number of steps between each update of the console output.
  
